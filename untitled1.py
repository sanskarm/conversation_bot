# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tE_iJys0u7lC1TNHDR4v7j3Kq0b-fJYR
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

pip install SoundFile

pip install data

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import math
import random
import numpy as np
from six.moves import xrange
import tensorflow as tf
import soundfile
import textaudiofeatures as featurizer
print(tf.__version__)

class AudioConfig(object):
  def__init__(self,sample_rate,window_len,stride_len,normalize=False):
  self.sample_rate = sample_rate
  self.window_len = window_len
  self.stride_len = stride_len
  self.normalize = normalize

class DatasetConfig(object):
  def__init__(self,audio_config,data_path,vocab_file_path, sortagrad):
  self.audio_config = audio_config
  assert tf.gfile.Exists(data_path)
  assert tf.gfile.Exists(vocab_file_path)
  self.data_path = data_path
  self.vocab_file_path = vocab_file_path
  self.sortagrad = sortagrad

def _normalize_audio_feature(audio_feature):
  mean = np.mean(audio_feature, axis=0)
  var = np.var(audio_feature, axis=0)
  normalized = (audio_feature-mean)/(np.sqrt(var)+1e-6)
  return normalized

def _preprocess_audio(audio_file_path, audio_featurizer, normalize):
  data,_ = soundfile.read(audio_file_path)
  feature = featurizer.spectogram_features(data,audio_featurizer.sample_rate,audio_featurizer.stride_len,audio_featurizer.window_len)
  if normalize:
    feature = normalize_audio_feature(feature)
  feature = np.expand_dims(feature,axis=2)
  return feature

def _preprocess_data(file_path):
  with tf.gfile.Open(file path, "r") as f:
    lines = f.read().splitlines()
  lines = lines[1:]
  lines = [line.split("\t",2) for line in lines]
  lines.sort(key=lambda item: int(item[1]))

  return [tuple(line) for line in lines]

class DeepSpeechDataset(object):
  def__init__(self,dataset_config):
    self.config = dataset_config
    self.audio_featurizer = featurizer.Audio_Featurizer(sample_rate=self.config.audio_config.sample_rate,window_len=self.config.audio_config.window_len,stride_len=self.config.audio_config.stride_len)
    self.text_featurizer = featurizer.TextFeaturizer(vocab_file = self.config.vocab_file_path)
    self.speech_labels = self.text_featurizer.speech_labels
    self.entries = _preprocess_data(self.config.data_path)
    self.num_feature_bins = 161

def batch_wise_dataset_shuffle(entries, epoch_index, sortagrad, batch_size):
  shuffled_entries = []
  if epoch_index==0 and sortagrad:
    shuffled_entries = entries
  else:
    max_buckets = int(math.floor(len(entries)/batch_size))
    total_buckets = [i for i in xrange(max_buckets)]
    random.shuffle(total_buckets)
    shuffled_entries = []
    for i in total_buckets:
      shuffled_entries.extend(entries[i * batch_size : (i + 1) * batch_size])
    shuffled_entries.extend(entries[max_buckets*batch_size])

  return shuffled_entries

def input_fn(batch_size,deep_speech_dataset,repeat=1):
  data_entries = deep_speech_dataset.entries
  num_feature_bins = deep_speech_dataset.num_feature_bins
  audio_featurizer = deep_speech_dataset.audio_featurizer
  feature_normalize = deep_speech_dataset.config.audio_config.normalize
  text_featurizer = deep_speech_dataset.text_featurizer

def _gen_data():
  for audio_file, _, transcript in data_entries:
      features = _preprocess_audio(
          audio_file, audio_featurizer, feature_normalize)
      labels = featurizer.label_feature(
          transcript, text_featurizer.token_to_index)
      input_length = [features.shape[0]]
      label_length = [len(labels)]
      yield (
          {
              "features": features,
              "input_length": input_length,
              "label_length": label_length
          },
          labels)

dataset = tf.data.Dataset.from_generator(
      _gen_data,
      output_types=(
          {
              "features": tf.float32,
              "input_length": tf.int32,
              "label_length": tf.int32
          },
          tf.int32),
      output_shapes=(
          {
              "features": tf.TensorShape([None, num_feature_bins, 1]),
              "input_length": tf.TensorShape([1]),
              "label_length": tf.TensorShape([1])
          },
          tf.TensorShape([None]))
  )
  dataset = dataset.repeat(repeat)
  dataset = dataset.padded_batch(
      batch_size=batch_size,
      padded_shapes=(
          {
              "features": tf.TensorShape([None, num_feature_bins, 1]),
              "input_length": tf.TensorShape([1]),
              "label_length": tf.TensorShape([1])
          },
          tf.TensorShape([None]))
  )
  dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
  return dataset

