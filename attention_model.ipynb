{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCd8C1n1MeVg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
        "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model, Model\n",
        "import keras.backend as K"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZflM5lwWV2nh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "c7336856-0875-44d2-ce46-7c2379cfe0e1"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 03:18:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... failed: Connection timed out.\n",
            "Retrying.\n",
            "\n",
            "--2020-07-08 03:19:06--  (try: 2)  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-CajtouNA8O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "7965ce1f-f23d-4630-cbf0-5b31c26df43c"
      },
      "source": [
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-08 02:37:00--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz [following]\n",
            "--2020-07-08 02:37:01--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3663376519 (3.4G) [application/gzip]\n",
            "Saving to: ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz’\n",
            "\n",
            "download.php?f=Open 100%[===================>]   3.41G  17.8MB/s    in 3m 25s  \n",
            "\n",
            "2020-07-08 02:40:27 (17.1 MB/s) - ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz’ saved [3663376519/3663376519]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "timWF6dhMh-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir('/tmp')\n",
        "#os.mkdir('/tmp/word_embeddings')\n",
        "os.mkdir('/tmp/lines')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSAAEDWoMoSc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "532b59e2-4b01-476e-9089-40260bdeb8bb"
      },
      "source": [
        "!unzip glove.6B.zip -d /tmp/word_embeddings\n",
        "os.listdir('/tmp/word_embeddings')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open glove.6B.zip, glove.6B.zip.zip or glove.6B.zip.ZIP.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0014954406ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip glove.6B.zip -d /tmp/word_embeddings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/tmp/word_embeddings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/word_embeddings'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_rzQDPwM4qW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gunzip -k download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz\n",
        "!split -a 3 -l 100000 download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en /tmp/lines/lines-"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7naiO_mJP3m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/tmp/word_embeddings/glove.6B.100d.txt',\"r\") as f:\n",
        "  word_to_vec_map = {}\n",
        "  for line in f:\n",
        "    line = line.strip().split()\n",
        "    new_word = line[0]\n",
        "    word_to_vec_map[new_word] = np.asarray(line[1:],dtype = 'float64')\n",
        "print('Found %s word vectors'%len(word_to_vec_map))\n",
        "print(word_to_vec_map[\"fuck\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0OPzmXXVyis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def filter_line(line):\n",
        "  line = line.lower()\n",
        "  line.strip()\n",
        "  line = line.replace(\"\\n\",\" \")\n",
        "  line = line.replace(\",\",\"\")\n",
        "  line = line.replace(\".\",\"\")\n",
        "  line = line.replace(\"?\",\"\")\n",
        "  line = line.replace(\"<\",\"\")\n",
        "  line = line.replace(\">\",\"\")\n",
        "  line = line.replace(\"/\",\"\")\n",
        "  line = line.replace(\";\",\"\")\n",
        "  line = line.replace(\":\",\"\")\n",
        "  line = line.replace(\"'\",\"\")\n",
        "  line = line.replace(\"-\",\" \")\n",
        "  line = line.replace(\"+\",\"\")\n",
        "  line = line.replace(\"=\",\"\")\n",
        "  line = line.replace(\"!\",\"\")\n",
        "  line = line.replace(\"  \",\" \")\n",
        "  line = \"<startseq> \" + line + \"<endseq>\"\n",
        "  return line"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq5_i8CvbUt0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = []\n",
        "for files in os.listdir('/tmp/lines'):\n",
        "  path = os.path.join('/tmp/lines',files)\n",
        "  f = open(path)\n",
        "  i=0\n",
        "  for line in f:\n",
        "    line = filter_line(line)\n",
        "    if i==100000:\n",
        "      break\n",
        "    dataset.append(line)\n",
        "    i =i+1\n",
        "  if i==100000:\n",
        "    break"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URiEM6eehPgS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebada697-3245-4a01-9cfe-50d2246d9697"
      },
      "source": [
        "print(dataset[50001])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<startseq> but <endseq>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA7ktJzcl29Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oov_token = \"<OOV>\"\n",
        "trunc_type = 'post'\n",
        "pad_type = 'post'\n",
        "max_len = 20"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YVwxfwFl_x0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc968ccb-4809-4500-faa3-76db6b247f75"
      },
      "source": [
        "tokenizer = Tokenizer(oov_token = oov_token)\n",
        "tokenizer.fit_on_texts(dataset)\n",
        "word_index = tokenizer.word_index\n",
        "sequence = tokenizer.texts_to_sequences(dataset)\n",
        "padded_sequence = pad_sequences(sequence, maxlen=max_len,padding = pad_type, truncating = trunc_type)\n",
        "vocab_size = len(word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwcM3Q89Kuzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_word_map = {}\n",
        "for word,index in word_index.items():\n",
        "  index_to_word_map[index] = word"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XWL1DfzRtJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input = []\n",
        "output = []\n",
        "for j in range(0,99999,2):\n",
        "  input_temp=padded_sequence[j]\n",
        "  output_temp=padded_sequence[j+1]\n",
        "  input.append(input_temp)\n",
        "  output.append(output_temp)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imneZRiOMrKA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_to_vec_map.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-Zr_aD2awnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "65af4dfa-8148-4cc1-ae60-7691998d229c"
      },
      "source": [
        "for word, i in word_index.items():\n",
        "    embedding_vector = word_to_vec_map.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector \n",
        "embedding_layer = Embedding(vocab_size,50,weights=[embedding_matrix],input_length=20,trainable=False)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-51ada80e4b57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0membedding_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_vec_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0membedding_vector\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0membedding_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0membedding_matrix\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'word_to_vec_map' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xk4YrvRiOLzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "20809d2f-0b03-414e-d769-ce05b07d49fa"
      },
      "source": [
        "batch_size = 40\n",
        "embedding_dim = 100\n",
        "print(len(input))\n",
        "print(len(output))\n",
        "max_length = 20"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000\n",
            "50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYKC0ZltpeLZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Decoder_LSTM = LSTM(256, return_state = True)\n",
        "final_layer = Dense(vocab_size,activation = 'softmax')\n",
        "repeator = RepeatVector(max_length)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"relu\")\n",
        "activator = Activation('tanh', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1o4JaVn7qR2y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention(a,s_1):\n",
        "  s_1 = repeator(s_1)\n",
        "  concat = concatenator([a, s_prev])\n",
        "  ie = densor1(concat)\n",
        "  energy = densor2(ie)\n",
        "  alpha = activator(energy)\n",
        "  context = dotor([alpha,a])\n",
        "\n",
        "  return context"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_GOLK4qRE-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  T_x = 20\n",
        "  T_y = 20\n",
        "  na = 128\n",
        "  ns = 256\n",
        "  s0 = np.zeros((10000, n_s))\n",
        "  c0 = np.zeros((10000, n_s))\n",
        "\n",
        "  reply = []\n",
        "\n",
        "  glove_vector = embedding_layer(X)\n",
        "  a = Bidirectional(LSTM(units = na,return_sequences=True))(glove_vector)\n",
        "\n",
        "  s = s0\n",
        "  c = c0\n",
        "  for i in range (T_y):\n",
        "    context = attention(a,s0)\n",
        "    s0,_,c = Decoder_LSTM(input= context,intitial_state = [s,c])\n",
        "    word = final_layer(s)\n",
        "    reply.append(word)\n",
        "\n",
        "    Model = model(inputs = [X],output = reply)\n",
        "\n",
        "    return Model\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdFJCOpFpF69",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "209ca75c-9087-469f-8854-67f038c35ba9"
      },
      "source": [
        "model = model()\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-f83b1548ef06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-0450155d7f63>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mglove_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBidirectional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_sequences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglove_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_layer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZcfLBTIrvwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = Adam(learning_rate=0.0005, beta_1=0.9, beta_2=0.999,  decay = 0.001)\n",
        "model.compile(opt, loss = \"sparse_categorical_crossentropy\", metrics = ['accuracy'])\n",
        "\n",
        "outputlabels = list(outputlabels.swapaxes(0,1)\n",
        "model.fit([input], output_labels, batch_size = 100, epochs = 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u0TSY_2uURr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def beam_search_decoder(predictions, top_k = 3):\n",
        "\n",
        "    output_sequences = [([], 0)]\n",
        "    \n",
        "    for token_probs in predictions:\n",
        "        new_sequences = []\n",
        "        token_probs = token_probs.reshape(5000 ,)\n",
        "        for old_seq, old_score in output_sequences:\n",
        "            for char_index in range(len(token_probs)):\n",
        "                new_seq = old_seq + [char_index]\n",
        "                new_score = old_score + math.log(token_probs[char_index])\n",
        "                new_sequences.append((new_seq, new_score))\n",
        "                \n",
        "        output_sequences = sorted(new_sequences, key = lambda val: val[1], reverse = True)\n",
        "        output_sequences = output_sequences[:top_k]\n",
        "        \n",
        "    return output_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOBC0IQ8tNMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "you = []\n",
        "you_sequence = tokenizer.texts_to_sequences(you)\n",
        "padded = pad_sequences(you_sequence,maxlen=20, truncating = 'post',padding = 'post')\n",
        "reply = model.predict([padded])\n",
        "reply = beam_search(reply)\n",
        "print(reply)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}